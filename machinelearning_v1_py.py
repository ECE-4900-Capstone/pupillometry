# -*- coding: utf-8 -*-
"""MachineLearning_V1.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t_hp5rApqrRh3u-MBb7LQivw1839kWX3
"""

# Commented out IPython magic to ensure Python compatibility.
# JAZHL Research Team
# ECE 4900 Capstone 2
# Authored by Jacob Haehn, Hayden Clark

# Imports
import csv
import numpy as np
import sklearn as sk
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

# Google Drive access for data
from google.colab import drive
drive.mount('/content/drive')

# High Level ML Algorithm
def train_ML(inputFile, finalizedModelFilepath):
    # Extract Data
    X, y = extract_data(inputFile)

    # Optional step for verifying initial accuracy of log_reg
    # training_accuracy_check()

    # Perform ML training
    trainedModel = cross_validation(X, y, finalizedModelFilepath)

    return trainedModel

def run_ML_predict(finalizedModelFilepath, testPupilRadius)
    # Load Trained Model
    trainedModel = load_trained_model(finalizedModelFilepath)

    # Make Cognitive Load Predictions
    cognitiveLoadPrediction = logreg.predict(testPupilRadius)

    return cognitiveLoadPredictions

# Functions
def extract_data(inputFile): # Function used for data extraction

  # Define columns for data extraction
  frameNumberCol = 0
  radiusChangeCol = 1
  groundTruthCol = 2

  # Open CSV file
  with open(inputFile, newline='') as csvfile:
        # Read CSV
        csv_data = list(csv.reader(csvfile, delimiter=','))

        # Extract rows of CSV and store in list
        frameNumberList = []
        radiusChangeList = []
        groundTruthList = []
        for row in csv_data:

          frameNumberList.append(row[frameNumberCol])
          radiusList.append(row[radiusChangeCol])
          groundTruthList.append(row[groundTruthCol])

        print(frameNumberList)
        print(radiusList)
        print(groundTruthList)

        return radiusList, groundTruthList

def training_accuracy_check(X, y)
    # Log. Reg. solver
    logreg = linear_model.LogisticRegression(C=1e5, solver = 'liblinear')
    logreg.fit(X,y)

    # Check accuracy of classifier (should be 100% on the training data)
    yhat = logreg.predict(Xs)
    acc = np.mean(yhat == y)
    print("Accuracy on training data = %f" % acc)

def cross_validation(X, y, finalizedModelFilepath):
    # Cross-Validation (need to edit variables)

    import sklearn
    from sklearn.metrics import precision_recall_fscore_support
    from sklearn.model_selection import KFold
    import pickle


    nfold = 10
    kf = KFold(n_splits=nfold,shuffle=True)
    prec = []
    rec = []
    f1 = []
    acc = []
    for train, test in kf.split(Xs):
        # Get training and test data
        Xtr = X[train,:]
        ytr = y[train]
        Xts = X[test,:]
        yts = y[test]

        # Fit a model
        print("Fitting Model " + train + "," + test "...")
        logreg.fit(Xtr, ytr)
        yhat = logreg.predict(Xts)

        # Measure performance
        print("Measuring Performance " + train + "," + test "..."))
        preci,reci,f1i,_= precision_recall_fscore_support(yts,yhat,average='binary')
        prec.append(preci)
        rec.append(reci)
        f1.append(f1i)
        acci = np.mean(yhat == yts)
        acc.append(acci)

    print("Finished training")
    # Take average values of the metrics
    precm = np.mean(prec)
    recm = np.mean(rec)
    f1m = np.mean(f1)
    accm= np.mean(acc)

    # Compute the standard errors
    prec_se = np.std(prec,ddof=1)/np.sqrt(nfold)
    rec_se = np.std(rec,ddof=1)/np.sqrt(nfold)
    f1_se = np.std(f1,ddof=1)/np.sqrt(nfold)
    acc_se = np.std(acc,ddof=1)/np.sqrt(nfold)

    print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))
    print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))
    print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))
    print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))

    print("Saving model to " + finalizedModelFilepath)
    pickle.dump(logreg, open(finalizedModelFilepath, 'wb'))

    return logreg

def load_trained_model(finalizedModelFilepath)
    loaded_model = pickle.load(open(finalizedModelFilepath, 'rb'))
    result = loaded_model.score(X_test, Y_test)
    print(result)

    return loaded_model


if __name__ == '__main__':
    inputFile = '/content/drive/MyDrive/College/ECE 4900 3900/ECE 4900 Materials/Code/radius_data.csv'
    extract_data(inputFile)

# Data Loading

# Load data from Drive
inputFile = '/content/drive/MyDrive/Shared with me/ECE 4900 3900/ECE 4900 Materials/Code/radius_data.csv'
extract_data(inputFile)
df = pd.read_csv(data,index_col=0)
df.head(6)

# Data Structoring and Preprocessing

# Load data into dataframe
df = ...

# Visualize first 6 data entries
df.head(6)

# Need to handle missing values? http://pandas.pydata.org/pandas-docs/stable/missing_data.html
# df1 = df.fillna(df.mean())    Fill missing val. w/ mean of non-missing

# Define X as independant variable (pupil data), y as cognitive load classification (low/high)
X, y = extract_data(inputFile)

# Log. Reg. solver
logreg = linear_model.LogisticRegression(C=1e5, solver = 'liblinear')
logreg.fit(X,y)

# Check accuracy of classifier (should be 100% on the training data)
yhat = logreg.predict(Xs)
acc = np.mean(yhat == y)
print("Accuracy on training data = %f" % acc)

# Cross-Validation (need to edit variables)

import sklearn
from sklearn.metrics import precision_recall_fscore_support
from sklearn.model_selection import KFold

nfold = 10
kf = KFold(n_splits=nfold,shuffle=True)
prec = []
rec = []
f1 = []
acc = []
for train, test in kf.split(Xs):
    # Get training and test data
    Xtr = Xs[train,:]
    ytr = y[train]
    Xts = Xs[test,:]
    yts = y[test]

    # Fit a model
    logreg.fit(Xtr, ytr)
    yhat = logreg.predict(Xts)

    # Measure performance
    preci,reci,f1i,_= precision_recall_fscore_support(yts,yhat,average='binary')
    prec.append(preci)
    rec.append(reci)
    f1.append(f1i)
    acci = np.mean(yhat == yts)
    acc.append(acci)

# Take average values of the metrics
precm = np.mean(prec)
recm = np.mean(rec)
f1m = np.mean(f1)
accm= np.mean(acc)

# Compute the standard errors
prec_se = np.std(prec,ddof=1)/np.sqrt(nfold)
rec_se = np.std(rec,ddof=1)/np.sqrt(nfold)
f1_se = np.std(f1,ddof=1)/np.sqrt(nfold)
acc_se = np.std(acc,ddof=1)/np.sqrt(nfold)

print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))
print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))
print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))
print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))